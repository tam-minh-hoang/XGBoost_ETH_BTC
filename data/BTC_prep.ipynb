{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5974c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c57cdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 summary:\n",
      "- Shape: (3253, 8)\n",
      "- Date range: 2017-01-01 -> 2025-11-27\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "df = pd.read_csv(\"BTC_raw.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\").set_index(\"date\")\n",
    "print(\"Step 0 summary:\")\n",
    "print(f\"- Shape: {df.shape}\")\n",
    "print(f\"- Date range: {df.index.min().date()} -> {df.index.max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafc4406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate date count: 0\n",
      "Step 0 summary:\n",
      "- Shape after cleaning: (3253, 8)\n",
      "- Date range: 2017-01-01 -> 2025-11-27\n"
     ]
    }
   ],
   "source": [
    "# Keep the last data for duplicated dates\n",
    "dup_count = df.index.duplicated(keep=False).sum()\n",
    "print(f\"Duplicate date count: {dup_count}\")\n",
    "\n",
    "df = df[~df.index.duplicated(keep=\"last\")]\n",
    "\n",
    "print(\"Step 0 summary:\")\n",
    "print(f\"- Shape after cleaning: {df.shape}\")\n",
    "print(f\"- Date range: {df.index.min().date()} -> {df.index.max().date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc93b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- BTC df shape:  (3253, 5)\n",
      "- SPX df shape:  (2239, 1)\n",
      "- GOLD df shape: (2239, 1)\n",
      "- DXY df shape:  (2242, 1)\n"
     ]
    }
   ],
   "source": [
    "btc_df  = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].copy()\n",
    "\n",
    "spx_df  = df[[\"SP500\"]].dropna()\n",
    "gold_df = df[[\"GOLD\"]].dropna()\n",
    "dxy_df  = df[[\"DXY\"]].dropna()\n",
    "\n",
    "print(f\"- BTC df shape:  {btc_df.shape}\")\n",
    "print(f\"- SPX df shape:  {spx_df.shape}\")\n",
    "print(f\"- GOLD df shape: {gold_df.shape}\")\n",
    "print(f\"- DXY df shape:  {dxy_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67115e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_price_features(df, price_col, prefix):\n",
    "\n",
    "    out = df.copy()    \n",
    "\n",
    "    # Log price\n",
    "    log_col = f\"{prefix}_log_price\"\n",
    "    out[log_col] = np.log(out[price_col])\n",
    "\n",
    "    # Returns\n",
    "    for h in [1, 5, 20]:\n",
    "        out[f\"{prefix}_ret_{h}d\"] = out[log_col].diff(h)\n",
    "\n",
    "    # Volatility\n",
    "    out[f\"{prefix}_vol_20d\"] = out[f\"{prefix}_ret_1d\"].rolling(20).std()\n",
    "\n",
    "    # Momentum (price change over 10 days)\n",
    "    out[f\"{prefix}_mom_10d\"] = out[log_col].diff(10)\n",
    "\n",
    "    # Trend: moving averages\n",
    "    for w in [10, 20, 50]:\n",
    "        out[f\"{prefix}_sma{w}\"] = out[log_col].rolling(w).mean()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c311cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 summary:\n",
      "- BTC feat shape:   (3253, 14)\n",
      "- SPX feat shape:   (2190, 10)\n",
      "- GOLD feat shape:  (2190, 10)\n",
      "- DXY feat shape:   (2193, 10)\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering\n",
    "btc_feat  = add_price_features(btc_df,  \"close\",      \"btc\")\n",
    "spx_feat  = add_price_features(spx_df,  \"SP500\",  \"SP500\").dropna()\n",
    "gold_feat = add_price_features(gold_df, \"GOLD\", \"GOLD\").dropna()\n",
    "dxy_feat  = add_price_features(dxy_df,  \"DXY\",  \"DXY\").dropna()\n",
    "\n",
    "print(\"Step 2 summary:\")\n",
    "print(f\"- BTC feat shape:   {btc_feat.shape}\")\n",
    "print(f\"- SPX feat shape:   {spx_feat.shape}\")\n",
    "print(f\"- GOLD feat shape:  {gold_feat.shape}\")\n",
    "print(f\"- DXY feat shape:   {dxy_feat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74faa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_macro(left, right, prefix):\n",
    "    cols = [c for c in right.columns if c.startswith(prefix)]\n",
    "    temp = right[cols].sort_index()\n",
    "\n",
    "    merged = pd.merge_asof(\n",
    "        left.sort_index(),\n",
    "        temp,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        direction=\"backward\"\n",
    "    )\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d01637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 summary:\n",
      "- Full feature df shape: (3253, 44)\n",
      "- Date range: 2017-01-01 -> 2025-11-27\n"
     ]
    }
   ],
   "source": [
    "# merge macro features onto BTC timeline\n",
    "full = btc_feat.copy()\n",
    "\n",
    "full = merge_macro(full, spx_feat,  \"SP500\")\n",
    "full = merge_macro(full, gold_feat, \"GOLD\")\n",
    "full = merge_macro(full, dxy_feat,  \"DXY\")\n",
    "\n",
    "print(\"Step 3 summary:\")\n",
    "print(f\"- Full feature df shape: {full.shape}\")\n",
    "print(f\"- Date range: {full.index.min().date()} -> {full.index.max().date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fae5e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 summary:\n",
      "- NaNs in y_price_next: 2\n",
      "- NaNs in y_log_price_next: 2\n",
      "- NaNs in y_ret_1d_next: 1\n",
      "- NaNs in y_log_ret_1d_next: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katha\\AppData\\Local\\Temp\\ipykernel_39396\\913752856.py:2: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  full[\"btc_ret_1d_arith\"] = full[\"close\"].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Set targets\n",
    "full[\"btc_ret_1d_arith\"] = full[\"close\"].pct_change()\n",
    "full[\"y_price_next\"]        = full[\"close\"].shift(-1)\n",
    "full[\"y_log_price_next\"]    = full[\"btc_log_price\"].shift(-1)\n",
    "full[\"y_ret_1d_next\"]       = full[\"btc_ret_1d_arith\"].shift(-1)\n",
    "full[\"y_log_ret_1d_next\"]   = full[\"btc_ret_1d\"].shift(-1)   # btc_ret_1d is log return\n",
    "\n",
    "target_cols = [\n",
    "    \"y_price_next\",\n",
    "    \"y_log_price_next\",\n",
    "    \"y_ret_1d_next\",\n",
    "    \"y_log_ret_1d_next\",\n",
    "]\n",
    "\n",
    "print(\"Step 4 summary:\")\n",
    "for c in target_cols:\n",
    "    print(f\"- NaNs in {c}: {full[c].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09c11768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 summary:\n",
      "- Rows before dropna: 3253\n",
      "- Rows after dropna:  3177\n",
      "- Date range: 2017-03-15 -> 2025-11-24\n"
     ]
    }
   ],
   "source": [
    "# Drop NA\n",
    "before = full.shape[0]\n",
    "full_ml = full.dropna()\n",
    "after = full_ml.shape[0]\n",
    "\n",
    "print(\"Step 5 summary:\")\n",
    "print(f\"- Rows before dropna: {before}\")\n",
    "print(f\"- Rows after dropna:  {after}\")\n",
    "print(f\"- Date range: {full_ml.index.min().date()} -> {full_ml.index.max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b0ed294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "target_cols = [\n",
    "    \"y_price_next\",\n",
    "    \"y_log_price_next\",\n",
    "    \"y_ret_1d_next\",\n",
    "    \"y_log_ret_1d_next\",\n",
    "]\n",
    "\n",
    "def make_xy(df, target_col):\n",
    "    X = df.drop(columns=target_cols)  # all features stay\n",
    "    y = df[target_col]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de72565",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ml = full_ml.rename(columns=lambda x: x[4:] if x.startswith(\"btc_\") else x)\n",
    "full_ml = full_ml.rename(columns={\"ret_1d\": \"log_ret\"})\n",
    "full_ml = full_ml.rename(columns={\"SP500_ret_1d\": \"SP500_lret\"})\n",
    "full_ml = full_ml.rename(columns={\"GOLD_ret_1d\": \"GOLD_lret\"})\n",
    "full_ml = full_ml.rename(columns={\"DXY_ret_1d\": \"DXY_lret\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff0bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ml.to_csv(\"../BTC_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cqf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
